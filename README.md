## SFFNet: A Wavelet-Based Spatial and Frequency Domain Fusion Network for Remote Sensing Segmentation

[![DOI](https://img.shields.io/badge/DOI-10.1109/tgrs.2024.3427370-blue.svg)](https://doi.org/10.1109/tgrs.2024.3427370)
[![Link](https://img.shields.io/badge/IEEE-Transactions-orange.svg)](https://ieeexplore.ieee.org/document/10596303)
[![PDF](https://img.shields.io/badge/ğŸ“„_PDF_Download-FF5733.svg)](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10596303)

------------------------------

## ğŸ“‘ Table of Contents

- [ğŸ“š Introduction](#-introduction)
- [ğŸ“– Abstract](#-abstract)
- [ğŸ—ï¸ Architecture Diagram](#ï¸-architecture-diagram)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸš€ Quick Start](#-quick-start)
  - [1. Installation](#1installation)
  - [2. Prepare Dataset](#2prepare-dataset)
  - [3. Training](#3training)
  - [4. Evaluate on Vaihingen dataset](#4evaluate-on-vaihingen-dataset)
- [ğŸ™ Acknowledgment](#acknowledgment)

-------------------------------

## ğŸ“š Introduction

Official implementation of **SFFNet**, a novel dual-branch network that leverages wavelet transform for spatial and frequency domain fusion in remote sensing image segmentation.


--------------------
## ğŸ“– Abstract

This paper propose SFFNet, a novel framework for remote sensing image segmentation that effectively fuses spatial and frequency domain information. It employs a two-stage design: spatial feature extraction followed by a dual-domain mapping stage. Key innovations include a Wavelet Transform Feature Decomposer (WTFD) for frequency analysis and a Multiscale Dual-representation Alignment Filter (MDAF) to bridge domain gaps, achieving state-of-the-art mIoU scores of 84.80% and 87.73% on benchmark datasets. 

-------------------------------

## ğŸ—ï¸ Architecture Diagram

![SFFNet](./Architecture.png "SFFNet Architecture Diagram")
*The proposed two-stage spatial-frequency fusion framework of SFFNet.*

--------------------

## ğŸ“ Project Structure

Prepare the following folders to organize this repo:

```plaintext
SFFNet-main/ [Remote Sensing Segmentation Framework]
â”œâ”€â”€ data/                       # dataset
â”‚   â”œâ”€â”€ LoveDA/                 
â”‚   â”œâ”€â”€ potsdam/                
â”‚   â””â”€â”€ vaihingen/              
â”‚
â”œâ”€â”€ fig_results/                # Experimental results and visualization
â”‚   â”œâ”€â”€ loveda/                 
â”‚   â”œâ”€â”€ potsdam/                
â”‚   â””â”€â”€ vaihingen/              
â”‚
â”œâ”€â”€ GeoSeg/                     # Main source code package
â”‚   â”œâ”€â”€ config/                 # Configuration files
â”‚   â””â”€â”€ geoseg/                 
â”‚       â”œâ”€â”€ datasets/           # Data loading and preprocessing modules
â”‚       â”œâ”€â”€ losses/             # Loss function implementations
â”‚       â””â”€â”€ models/             # Model architectures and components
â”‚   â”œâ”€â”€ tools/                  # Execution scripts
â”‚   â”œâ”€â”€ inference_huge_image.py # Large image inference script
â”‚   â”œâ”€â”€ inference_uavid.py  
â”‚   â”œâ”€â”€ loveda_test.py          
â”‚   â”œâ”€â”€ potsdam_test.py         
â”‚   â”œâ”€â”€ train_supervision.py    # Main training script
â”‚   â””â”€â”€ vaihingen_test.py       # Vaihingen evaluation script
â”‚
â”œâ”€â”€ lightning_logs/             # PyTorch Lightning training logs
â”‚   â”œâ”€â”€ loveda/                 
â”‚   â”œâ”€â”€ potsdam/                
â”‚   â””â”€â”€ vaihingen/              
â”‚
â”œâ”€â”€ model_weights/              # Trained model checkpoints
â”‚   â”œâ”€â”€ loveda/                 
â”‚   â”œâ”€â”€ potsdam/                
â”‚   â””â”€â”€ vaihingen/              
â”‚
â”œâ”€â”€ pretrain_weights/           # Pre-trained backbone weights
â”œâ”€â”€ README.md                   
â””â”€â”€ requirements.txt            # Python environment dependencies
```
-------------------
## ğŸš€ Quick Start
This guide will help you set up the environment and run a basic training example on the Vaihingen dataset.

### 1.Installation

#### Clone the repository

```bash
git clone https://github.com/your-username/SFFNet.git
cd SFFNet
```

#### Install dependencies
Create and activate virtual environment (optional)

You can use either **Conda**
```bash
conda create -n sffnet python=3.8
conda activate sffnet
```
or **python's built-in venv**
```bash
python -m venv sffnet
source sffnet/bin/activate  # Linux/Mac
# sffnet\Scripts\activate  # Windows
```

Install dependencies
```bash
pip install -r requirements.txt
```
To install and use the wavelet analysis tools, see the official [pytorch_wavelets](https://github.com/fbcotter/pytorch_wavelets) documentation.

### 2.Prepare Dataset

#### ISPRS 2D Semantic Labeling Contest

- **Potsdam & Vaihingen**: Download the original datasets from the official website: [[Click Here](https://www.isprs.org/resources/datasets/benchmarks/UrbanSemLab/default.aspx)]
- **Preprocessed Vaihingen**: We provide the preprocessed Vaihingen dataset for direct use: [[Click Here](https://huggingface.co/datasets/yangys123333/RS_Image_Segmentation_Vaihingen/tree/main)]
- If you need to handle the dataset yourself, you can refer to this project:
 [GeoSeg](https://github.com/WangLibo1995/GeoSeg?tab=readme-ov-file)

#### Processed Vaihingen Dataset Structure
```plaintext
vaihingen/
â”œâ”€â”€ test/                          # Test set directory
â”‚   â”œâ”€â”€ images_1024/               # Test images
â”‚   â”œâ”€â”€ masks_1024/                # Test ground truth labels (single-channel)
â”‚   â””â”€â”€ masks_1024_rgb/            # Visualized labels (colorful, for human viewing)
â””â”€â”€ train/                         # Training set directory
    â”œâ”€â”€ images_1024/               # Training images
    â””â”€â”€ masks_1024/                # Training ground truth labels (single-channel)
```
### 3.Training
To train the model on the Vaihingen dataset, run:
```bash
python GeoSeg/train_supervision.py -c GeoSeg/config/vaihingen/sffnet.py
```

#### âš™ï¸ Parameter Explanation

| Parameter | Type | Default | Description | Required |
|:----------|:----:|:-------:|:------------|:---------|
| `-c` | string | required | Configuration file path | âœ…        |

You can create your own configuration file by using the template at `GeoSeg/config/vaihingen/sffnet.py` as a reference.


### 4.Evaluate on Vaihingen dataset

This script (`GeoSeg/{dataset}_test.py`) is used for evaluating trained segmentation models on test datasets with support for test-time augmentation (TTA).

#### Examples

```bash
python GeoSeg/vaihingen_test.py -c GeoSeg/config/vaihingen/sffnet.py -o fig_result/vaihingen -t --rgb
```

#### âš™ï¸ Evaluation Script Parameters

| Parameter | Short | Type | Default | Description | Required |
|:----------|:-----:|:----:|:-------:|:------------|:---------|
| `--config_path` | `-c` | string | None | Path to the configuration file | âœ… |
| `--output_path` | `-o` | string | None | Directory to save prediction masks | âœ… |
| `--tta` | `-t` | string | None | Test-time augmentation: `lr` (flips) or `d4` (flips+rotate+scale) | âŒ |
| `--rgb` | (None) | boolean | False | Output colorized RGB masks for visualization | âŒ |
-------------------------
## ğŸ™Acknowledgment

This repository is developed based on and extends the [GeoSeg](https://github.com/WangLibo1995/GeoSeg) framework. We gratefully acknowledge the contributions from the following open-source projects that form the foundation of our work:

- **[pytorch lightning](https://www.pytorchlightning.ai/)** - For scalable and reproducible deep learning training
- **[timm](https://github.com/rwightman/pytorch-image-models)** - For pre-trained backbone models and optimization techniques
- **[pytorch-toolbelt](https://github.com/BloodAxe/pytorch-toolbelt)** - For additional deep learning utilities and tools
- **[ttach](https://github.com/qubvel/ttach)** - For test-time augmentation capabilities
- **[catalyst](https://github.com/catalyst-team/catalyst)** - For high-level PyTorch utilities and training patterns
- **[mmsegmentation](https://github.com/open-mmlab/mmsegmentation)** - For semantic segmentation architectures and benchmarks
- **[pytorch_wavelets](https://github.com/fbcotter/pytorch_wavelets)** - For wavelet transform operations and frequency domain analysis

We extend our sincere appreciation to all the original authors and contributors of these projects for their valuable work.

--------------------------------------